{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be268f7-39ce-44d3-b0ad-89f260945e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/06 09:38:18 WARN Utils: Your hostname, group4-0 resolves to a loopback address: 127.0.0.1; using 192.168.2.91 instead (on interface ens3)\n",
      "24/03/06 09:38:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/06 09:38:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://group4-0:7077\") \\\n",
    "        .appName(\"DE-1-4-SparkSession\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd1639f-d7dd-4518-919e-4906dbca9f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- content_len: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- normalizedBody: string (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary_len: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit_df = spark_session.read.json(\"/home/ubuntu/input/corpus-webis-tldr-17.json\")\n",
    "temp_str = \"hdfs://localhost:9000/user/ubuntu/corpus-webis-tldr-17.json\"\n",
    "reddit_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd40589-e449-4659-93c0-1626c663aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pos = \"./opinion-lexicon-English/positive-words.txt\"\n",
    "path_neg = \"./opinion-lexicon-English/negative-words.txt\"\n",
    "positive_words = set()\n",
    "negative_words = set()\n",
    "with open(path_pos, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        positive_words.add(line.strip())\n",
    "with open(path_neg, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        negative_words.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de81bb4-fafe-4368-ad41-4f557e56683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(author='raysofdarkmatter', body=\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets.\\n\\nMoving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n\\nI think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n\\nNow we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans.\\n\\nLighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n\\nThere's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\\n\\ntl;dr: Shifting seasonal time is no longer worth it.\", content=\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\", content_len=178, id='c69al3r', normalizedBody=\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly. \\n tl;dr: Shifting seasonal time is no longer worth it. \\n\", subreddit='math', subreddit_id='t5_2qh0n', summary='Shifting seasonal time is no longer worth it.', summary_len=8, title=None)\n"
     ]
    }
   ],
   "source": [
    "print(reddit_df.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1380067e-f8ab-46f1-bcef-cb0cb4a04cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: string (nullable = true)\n",
      " |-- content_len: long (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary_len: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit_df = reddit_df.drop(\"author\", \"body\", \"normalizedBody\", \"id\", \"subreddit_id\", \"title\")\n",
    "reddit_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b07fcf6-dd74-480b-a1c0-60a5b1017105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_reddit_df = reddit_df.sample(False, 0.05)\n",
    "sampled_reddit_df = sampled_reddit_df.filter(sampled_reddit_df[\"subreddit\"] != \"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30421c52-2113-454b-a584-a9d6da873d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_positive_words = spark_session.sparkContext.broadcast(positive_words)\n",
    "broadcast_negative_words = spark_session.sparkContext.broadcast(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b72200-7629-43ec-b13f-f0849a1f8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(summary):\n",
    "    line = summary.lower()\n",
    "    line = re.sub(r\"[.,]\",'',line).split(\" \")\n",
    "    positive_count = sum([word in broadcast_positive_words.value for word in line])\n",
    "    negative_count = sum([word in broadcast_negative_words.value for word in line])\n",
    "    if positive_count > negative_count:\n",
    "        return (1,positive_count,negative_count, 1)\n",
    "    elif negative_count > positive_count:\n",
    "        return (-1,positive_count,negative_count, 1)\n",
    "    else:\n",
    "        return (0, positive_count, negative_count, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad30beb-c3f1-4bd6-892c-d2afd45b701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: string (nullable = true)\n",
      " |-- content_len: long (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary_len: long (nullable = true)\n",
      " |-- conotation: struct (nullable = true)\n",
      " |    |-- sentiment: integer (nullable = false)\n",
      " |    |-- positive_count: integer (nullable = false)\n",
      " |    |-- negative_count: integer (nullable = false)\n",
      " |    |-- number_of_tweets: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(sentiment=1, positive_count=1, negative_count=0, number_of_tweets=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/06 09:48:13 WARN BlockManagerMasterEndpoint: No more replicas available for broadcast_6_python !\n",
      "24/03/06 09:48:13 WARN BlockManagerMasterEndpoint: No more replicas available for broadcast_7_python !\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType, StructType, StructField\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"sentiment\", IntegerType(), False),\n",
    "    StructField(\"positive_count\", IntegerType(), False),\n",
    "    StructField(\"negative_count\", IntegerType(), False),\n",
    "    StructField(\"number_of_tweets\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "conotation_udf = udf(pre_process, schema)\n",
    "reddit_df_conotation = sampled_reddit_df.withColumn(\"conotation\", conotation_udf(\"summary\"))\n",
    "reddit_df_conotation.printSchema()\n",
    "print(reddit_df_conotation.first()['conotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3423ffcc-2032-4e9b-9b10-e37fad257b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(sentiment=0, positive_count=0, negative_count=0)\n",
      "Class only items dropped from high-lvl monsters.\n",
      "Row(sentiment=0, positive_count=0, negative_count=0)\n",
      "OPI Nail Envy!\n",
      "Row(sentiment=1, positive_count=2, negative_count=1)\n",
      "get a good CPA - they aren't that expensive but are 100% worth it\n",
      "Row(sentiment=0, positive_count=1, negative_count=1)\n",
      "just because you're close \"at times\" doesn't mean you didn't get stomped in a best of 5 that you lost 6 games in.\n",
      "Row(sentiment=0, positive_count=0, negative_count=0)\n",
      "It's a half-assed fan-art that literally put effort into one-half of the picture.\n",
      "Row(sentiment=0, positive_count=0, negative_count=0)\n",
      "it is possible to be in a race you didnt know you were in.\n",
      "Row(sentiment=-1, positive_count=4, negative_count=12)\n",
      "As if Sweep/Smash spec wasn't already borderline OP in PvP, prepare to see a lot more of them come 1.4 buffs. \n",
      " EDIT: Don't want to give the impression that I thought Focus spec was totally and absolutely broken. It does have weaknesses like lack of sustain and nothing to really fall back on if Smash doesn't hit (at least till the next cooldown). Also it's one of those specs that is very gear dependent, meaning with bad gear, it is very very bad because of the weaknesses above. But it's also a spec that gets exponentially better once you have awesome gear because everything is focused down to a single bursty AOE attack that automatically crits and is kinetic damage so Knights can completely ignore accuracy and crit rating and stack main stat, power, and surge (which explains the 6.7k+ hits). So again, didn't think it was broken, but did think it was a bit too strong pre 1.4. And now it's getting buffed. Sadface.jpg\n",
      "Row(sentiment=1, positive_count=2, negative_count=0)\n",
      "I get you think that through some fancy hand-waving suggesting the guy is gay (whether to his face or to each other) has some use.  I'm simply asking you to present evidence or a reasonable argument. \n",
      " I'm still waiting.\n",
      "Row(sentiment=1, positive_count=2, negative_count=1)\n",
      "is I'm all for it being somewhat more easily accessible than it was then, but if it's the same pill, it's definitely a hormonal whopper with side effects. \n",
      " Second edit: Thanks to everyone who actually sent me thoughtful replies instead of going \"no she's wrong, downvote herp derp\".\n",
      "Row(sentiment=0, positive_count=0, negative_count=0)\n",
      "My 10 month old molests a 5 year old. >>\n"
     ]
    }
   ],
   "source": [
    "for i in reddit_df_conotation.take(10):\n",
    "    print(i['conotation'])\n",
    "    #print(f\"Positive count: {i['conotation']['positive_count']}, negative count: {i['conotation']['negative_count']}\")\n",
    "    print(i['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "755b7c2f-86d3-42fb-b071-b8958e82582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AskReddit', (1, 1)),\n",
       " ('YouShouldKnow', (1, 1)),\n",
       " ('atheism', (0, 1)),\n",
       " ('todayilearned', (0, 1)),\n",
       " ('festivals', (-1, 1)),\n",
       " ('AskReddit', (1, 1)),\n",
       " ('zelda', (-1, 1)),\n",
       " ('Paleo', (0, 1)),\n",
       " ('AskReddit', (0, 1)),\n",
       " ('gallifrey', (1, 1))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = reddit_df_conotation.rdd.map(lambda x: (x[\"subreddit\"], (x[\"conotation\"][\"sentiment\"], x[\"conotation\"][\"number_of_tweets\"])))\n",
    "grouped.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cb5402f-f042-4733-b636-b7367547c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ENFP', (8, 22))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "grouped = grouped.reduceByKey(lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "grouped.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39d3642b-cd93-4b0c-aeb9-6f9eae7e83af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('leagueoflegends', (195, 5538)),\n",
       " ('buildapc', (193, 718)),\n",
       " ('summonerschool', (124, 710)),\n",
       " ('personalfinance', (91, 719)),\n",
       " ('magicTCG', (91, 516)),\n",
       " ('photography', (91, 278)),\n",
       " ('malefashionadvice', (82, 275)),\n",
       " ('wow', (74, 656)),\n",
       " ('seduction', (73, 434)),\n",
       " ('DotA2', (72, 1121))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = grouped.sortBy(lambda x: x[1], ascending = False)\n",
    "grouped.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "618f1fcb-6f3a-4a70-a6f0-d12559ba71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AskReddit', (-6043, 29300)),\n",
       " ('relationships', (-3739, 17765)),\n",
       " ('tifu', (-907, 2660)),\n",
       " ('relationship_advice', (-374, 2542)),\n",
       " ('trees', (-335, 2373)),\n",
       " ('politics', (-314, 1831)),\n",
       " ('atheism', (-299, 2174)),\n",
       " ('pics', (-294, 1764)),\n",
       " ('WTF', (-287, 1267)),\n",
       " ('funny', (-264, 2002))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = grouped.sortBy(lambda x: x[1], ascending = True)\n",
    "grouped.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4267b30-a3e0-456b-b1b2-7367ed93f91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
